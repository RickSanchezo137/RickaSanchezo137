# [返回](/)

# 八股文背诵版之—Redis篇

## Redis概述

### :point_right:**简单讲讲Redis？**

> 可以从几个点来说：概述、线程模型、数据结构、事务及持久化、主从和集群等来说

Redis是一个C语言编写的高性能非关系型数据库，Redis是内存数据库，因此读写速度非常快，常常被用作缓存。它的线程模型是基于单线程的Reactor模式，通过多路复用IO能够实现对网络IO请求的高效处理，同时内部对于客户端请求的执行又是单线程的，不会出现并发安全问题，避免了加锁等并发措施的开销。Redis包含几种基本的数据类型，包括string、set、hash、list、zset以及bitmap、hyperloglog、geometry，能够满足不同场景下的使用需求。Redis支持简单的事务。Redis也是支持持久化的，有两种形式的持久化方式：RDB和AOF。Redis能够实现主从复制、读写分离，也支持集群的搭建等等。总体来说，应该是目前使用比较广泛的非关系型数据库之一

### :point_right:**为什么要使用缓存？**

为了搭建支持高并发的高性能应用。首先是高性能方面，如果没有缓存，数据全部从数据库拿的话，会有大量的磁盘IO，一方面机器的负担比较大，另一方面频繁的磁盘IO也会影响取数据的效率，所以将一部分数据库中的数据放在缓存中，能够实现高速的数据读取，提升系统性能，降低服务器压力。其次是高并发方面，现在大多数服务都要求具有高并发的能力，如果大量的请求同时直接打在数据库上，数据库压力陡增，可能会造成一系列并发问题，甚至导致系统崩溃，丧失可用性，而将一部分请求用缓存直接返回，大大缓解了数据库的压力，在高并发情况下也能保证良好的可用性

### :point_right:**Redis优点？**

优点可以从线程模型、内存运行、数据结构、持久化机制和事务、集群的支持来说。缺点：内存数据库，容量受内存大小限制，只能用于较小数据量的存取；没有类似MySQL那样强大的事务和崩溃恢复功能等等

### :point_right:**Redis为什么这么快？**

1. 首先，Redis是运行在内存中的数据库，自然读写效率都非常高
2. 其次，Redis采用了基于多路复用的网络IO线程模型，能够高效并有序处理来自不同客户端的IO请求
3. 第三，Redis执行客户端请求是单线程的，相当于可以全力去读写数据，不用考虑加锁、不必要的上下文切换等开销
4. 最后，Redis的底层数据结构是经过精心设计的，能够在各个场景下维持高效率的存储和读取

### :point_right:**pipeline可能出现原子性问题吗？**

为了避免多个指令分批次进行造成多次不必要的网络传输，pipeline可以将指令打包在一起一次性传递过去。但如果传输的包大小超过了TCP的MTU，则会进行拆包，造成多个命令分开执行，所以说pipeline不能保证原子性

## Redis线程模型

### :point_right:**讲讲Redis线程模型？**

Redis是基于多路复用的网络IO，整个接收网络IO请求、执行客户端命令的流程靠文件事件处理器来实现，是一个单线程的Reactor模型。具体流程是：

1. 首先将服务端的server socket注册到多路复用器当中，这个多路复用器可以是select、poll或者epoll，并监听accept事件
2. 当客户端与服务器建立连接后，也就是事件分派主线程通过多路复用器监听到了事件，判断事件类型为accept，然后交给连接应答器处理*（也就是acceptCommandHandler函数）*，连接应答器会将这个连接的客户端socket注册到多路复用器当中，并且与AE_READABLE事件绑定
3. 当客户端发出相应的读写命令请求的时候，多路复用器监听到事件发生，判断事件类型为AE_READABLE，分派给命令读取处理器*（readQueryFromClient函数）*来执行，进行命令的读取、解析
4. 执行命令
5. 当执行完成后，主线程会将这个客户端socket与AE_WRITABLE绑定，客户端尝试获取相应的时候，就会触发相应事件并交付给命令回复处理器*（writeToClient函数）*处理，返回响应数据
6. 传输完响应数据之后，会解除这个客户端socket与AE_WRITABLE的绑定

上述这个流程都是在单线程内进行的，也就是说避免了加锁或上下文切换等开销，但在处理某一种事件过程中如果阻塞了或者执行很久，比如Redis的keys *指令，那么后面的请求过来也会陷入阻塞或等待，这是其中的一点缺陷

### :point_right:**为什么Redis 6之后又引入多线程了？**

Redis的开发者认为，使用瓶颈不在于cpu，而是在于网络IO和内存，内存可以增加，网络IO可以靠多线程来缓解。Redis 6.0中将命令的读取和解析，以及命令完成后响应数据写回客户端这两种IO，交给额外的IO处理线程来处理，真正的执行任务，还是在主线程内单线程顺序执行的

### :point_right:**讲讲epoll？**

epoll是一种多路复用的方式。我从头捋一遍吧，首先是Blocking IO，在等待IO就绪的阶段，会进入阻塞，因此一个线程只能处理一个连接，等到IO事件发生，线程才能继续运行；因此出现了Non-Blocking IO，等待IO就绪的阶段，如果连接没有事件发生，则会直接返回EWOULDBLOCK的标识，因此一个线程可以处理多个连接，通过轮询的方式，每个连接没有数据就返回EWOULDBLOCK，有数据就读取，缺点是这样用户线程需要不断轮询，不断进行系统调用，是一个开销比较大的行为；因此又出现了多路复用

多路复用有select、poll和epoll。select的参数有nfds、三种fd_set的结构：readfds、writefds、exceptfds，首先将需要监听的socket对应的文件描述符注册到对应的fd_set中，接着调用select函数，将这些fd_set从用户空间拷贝进内核空间，接着系统调用do_select函数，循环遍历小于nfds的文件描述符，如果哪个文件描述符对应的socket产生事件了，则*（通过回调函数）*唤醒*（socket等待队列中的）*线程，并且将fd_set从内核空间拷贝到用户空间，并且通过遍历的方式查询fd_set的哪个位置发生了事件，并作出相应处理。有这样几个缺陷：fd_set长度有限，为1024，因此管理的连接数有限；其次，有将fd_set在用户空间和内核空间来回拷贝的开销；最后，还有在内核空间和用户空间遍历fd_set的开销。1024的长度无法改变，除非修改内核源码并重新编译内核

poll在select的基础上进行了修改，将socket和监听的事件类型、真正发生的事件类型绑定在pollfd数组的节点当中，传入内核，没有1024长度的限制

poll还是会进行数据在内核用户空间之间的拷贝，以及轮询，于是epoll作出进一步改进，首先epoll_create在内核空间创建一个eventpoll实例，包含一个红黑树节点rdr，一个线程等待队列wq*（wait_queue）*，一个就绪队列rdllist。每次通过epoll_ctl注册一个socket的时候，会将对应的socket、指向wq的指针、指向rdllist的指针包装成一个epitem，并插入红黑树当中。接着调用epoll_wait，等待从就绪队列中拿取对应的socket并进行处理，当某个socket上发生事件的时候，会发生系统中断，调用提前注册好的中断函数ep_poll_callback，可以通过socket的等待队列找到对应的epitem，并将epitem从红黑树移动到就绪链表rdllist中，并检查线程等待队列里面有没有阻塞的线程，并唤醒。接着唤醒的线程就可以从rdllist中拿取对应的epitem，获取到socket和对应发生的事件并处理。用epoll来处理，避免了轮询和在用户和内核之间重复拷贝的开销，同样也不需要轮询，因此使用广泛

## Redis事务及持久化

### :point_right:**简单讲讲Redis事务？**

Redis事务是一种简单实现的事务，它将指令打包，然后顺序性的一次性执行。如果命令出错，则全部失败；如果运行出错，其他命令可以正常执行。相关命令：multi、exec、discard、watch、unwatch

### :point_right:**讲讲Redis持久化机制？**

持久化是指将内存中的数据存储到磁盘上，Redis有三种持久化方式，rdb、aof和混合持久化。rdb和aof分别生成dump.rdb和appendonly.aof文件，需要在redis.conf里面设置开启，开启后默认选择aof，否则选择rdb。rdb是二进制日志，读写效率高，占用空间较小，可通过save参数来设置持久化频率，或者调用save/bgsave指令或者关闭时也会持久化，调用bgsave的时候采用了copy on write写；aof是逻辑语句日志，读写效率相对较慢，更新频率快，占用内存较高，支持重写。混合方式是在aof重写时，重写成rdb的格式，提高效率

### :point_right:**讲讲Copy On Write？**

调用bgsave时，Redis进程会fork一个子进程进行持久化IO，采用了写时复制机制，也就是本来共用同一内存物理地址*（虚拟地址不同）*，当父进程中发生写操作，子进程会先拷贝一份出来放到其他位置，以免持久化时发生冲突，主线程不进行任何IO

### :point_right:**讲讲AOF重写？怎么重写的？会发生什么问题？**

aof重写是在aof文件大小超过阈值的时候，通过重写去缩小日志体积。rewrite的过程同样fork了一个子进程，但子进程不是在原文件上进行修改，而是创建一个新文件，并根据数据库的内容重新写精简的指令，比如直接用set；如果在重写过程中有指令进行操作，则将指令缓存到aof_rewrite_buf中，待到重写完成后再根据aof_rewrite_buf的内容追加修改，最后用新文件去替换旧文件

重写时会有大量的磁盘IO，此时如果no-appendfsync-on-rewrite设置为no，可能会造成竞争磁盘IO的现象发生，造成fsync “taking too long”的错误，此时可以选择设置为yes，但要承受重写期间宕机数据丢失的风险；或者采用主从架构，在从机上进行aof持久化

## Redis数据结构

### :point_right:**讲讲Redis的结构？**

Redis内部总体有两个字典数组结构，一个指向正常键值对，一个指向expires*（entry多一个expire字段）*，也就是设置了过期时间的键值对。每个字典数组包含ht[0]和ht[1]，ht[0]正常使用、ht[1]用于渐进式扩容时使用。ht[0]是一个hashtable，指向一个数组+链表的结构，链表的每个节点为dictEntry，存放键值对，值指向一个RedisObject

### :point_right:**讲讲Redis对象的结构？**

对于Redis中的键值对，值会指向一个RedisObject，包含一个4bits的type字段、4bits的encoding字段、24bits的lru字段、4字节的refcount字段和8字节的ptr指针，指向底层具体的数据结构

### :point_right:**Redis底层有哪些数据类型？底层原理？**

底层有string、set、hash、list、zset

string在value为整型或浮点型时，会尝试强转，然后底层用embstr或raw来存储。embstr用于短字符串的存储，一般不超过44字节，原因是这样的：对于Redis中的键值对，值都是由一个RedisObject对象头和它里面的ptr指针指向的数据结构来构成的，一个RedisObject包含int4的type，int4的encoding，int24的lru字段，int32的refcount字段，8个字节的ptr指针，大小总共为16个字节；embstr和raw底层都是SDS的数据结构，也就是RedisObject指向的结构，有一个字节的capacity、len、flags字段，以及一个byte[]数组content。假设一个空字符串，也就是byte数组只包含一个字节的'\0'，大小就有16+3+1=20字节了，而一般一次内存分配可以以64个字节为单位，如果长度大于44字节，就无法在64个字节内连续分配，就必须malloc两次，此时就认为是大字符串，为raw结构

set在底层采用的是intset*（encoding（哪一位的int）、length、int\<T>[] contents）*或hashtable，存放少量int类型用intset，存放了字符串或int超过一定阈值，转换为hashtable

hash在底层采用的是ziplist*（一些标志字段+若干个entry的紧凑型字节数组结构）*或hashtable，少量数据使用ziplist，超过阈值或元素长度大于阈值会转换成hashtable

list底层采用的是quicklist，它是一个循环双向链表的结构，每个链表节点接上一个ziplist

zset底层是skiplist+hashtable实现的，skiplist按照score进行排序，同时obj指针指向键值对的键对象，score存放分数，同时第一层的节点有个指向前面节点的指针，便于逆序排序，skiplist用于排序和范围查找；同时hashtable的entry的键也指向键对象，value存放分数，用于实现近似O(1)的精确查找

> ![116](imgs\redis\1.png)

此外，还有bitmap、hyperloglog、geo

### :point_right:**讲讲Redis渐进式扩容？**

Redis内部有两个大字典数组结构，也就是hashtable数组，其中一个存放正常的键值对，另一个存放expires。对于存放正常的键值对的字典数组，ht[0]是平时正常使用时用到的，ht[1]是扩容时用到的，扩容的时候采取渐进式扩容，具体过程是首先创建一个长度为2倍的dictEntry[]数组，并令ht[1]指向它，遍历ht[0]的dictEntry数组，并逐步将ht[0]对应索引上的链表移动到ht[1]，这里的逐步移动并不是一次性的，而是分多次的，在每次使用hash的时候或者每隔一段时间移动一次，全部移动完成后，令ht[0]指向ht[1]，所以叫渐进式rehash。使用这个的原因是避免长时间的扩容影响主线程的执行

## Redis淘汰策略&过期策略

### :point_right:**讲讲Redis过期键淘汰策略？**

Redis设置了过期时间的键会单独放在一个字典expires里面，淘汰就是从这个字典中淘汰。Redis采取了两种策略的结合，惰性策略和定时策略。定时策略就是每隔1秒扫描10次expires字典，随机取20个判断是否过期并淘汰，如果淘汰比例大于1/4，就继续选并淘汰，每次扫描的时间上限不超过25ms。惰性策略是每次访问到这个key的时候，判断是否过期并淘汰，可以离散地淘汰一些键

### :point_right:**讲讲Redis内存淘汰策略？**

**当进行写操作时**，发现内存不够用时或超出maxmemory指定的容量，Redis会进行键的淘汰，有allkeys-lru、allkeys-lfu、allkeys-random、volatile-lru、volatile-lfu、volatile-random、volatile-ttl和noeviction，可通过参数maxmemory-policy来指定。allkeys、volatile分别指从所有的数据中采样键、从expires中采样键，采样的个数可通过maxmemory-samples来指定，采样之后在这些键中根据指定规则进行淘汰。在lru规则下，RedisObject中有个24bits的lru字段，用于存放Redis时钟*（server.lruclock）*，每访问一次键就更新时钟，淘汰时淘汰最近最少访问的；在lfu规则下，lru字段用来存放16bits的ldt，last decrement time，和8bits的logc，logistic count，用logc来统计访问频次的对数，实现最少频次访问淘汰；random规则下随即移除；ttl规则下，直接比较expire字段，选择最早要过期的进行淘汰；noeviction不淘汰，超出内存阈值再写会返回错误信息

## Redis主从&集群

### :point_right:**Redis主从复制原理？主节点挂了怎么办？**

从节点指定主节点后，给主节点发送psync命令，主库会进行bgsave，存盘完成之后会向从库进行快照同步，也就是将rdb文件发送给从库。在这个过程中新来的修改命令会被存放在主库一个环形的buffer区域。快照同步完成后，从库清空内存，接着进行全量加载，加载完成之后，加载主库传过来的buffer中的指令，实现增量复制。如果快照同步时间太长，或者buffer太小，导致后面写的指令将前面的覆盖，会增量复制失败并重新触发快照同步，造成一个死循环，所以得合理设置buffer的大小

主节点挂了之后，从节点会原地待命，可以执行slaveof no one指令令自己重新变成主节点，但无法自动容错和恢复。可以采用哨兵模式监控这些Redis节点，主节点挂了会重新投票出一个从节点

### :point_right:**Redis集群方案讲一讲？**

如果是单机版Redis，一台服务器宕机就会导致整个服务不可用，其次还存在性能瓶颈、内存瓶颈等，影响性能。所以可以在多个服务器上放多个主节点，搭建集群，将数据分片存储，提升系统可用性。分片方式有客户端分片、代理分片和Redis-cluster的哈希槽。客户端分片是在客户端对键进行处理，令其路由到不同的redis节点，缺点是增加或删除节点的时候，所有客户端都要修改；代理分片是添加一个代理作为中间层，对客户端的请求在代理中进行路由，分发到不同节点；Redis-cluster支持客户端直接连接某个集群中的节点，路由时根据哈希槽的算法来分配请求，请求发送到错误节点会进行重定向，最好给每个主节点添加从节点，否则主节点宕机，集群就无法工作，有从节点的话，其他主节点会投票选举某个从节点成为新的主节点，超过一半投票率的会被选上

### :point_right:**Redis集群支持事务吗？**

集群不支持事务和批量操作，因为事务里面多个键可能分布在不同节点，这个问题可以靠hash tag一定程度上缓解

### :point_right:**什么是哈希槽？**

Redis-cluster划分了16384个槽，每个加入集群的节点，负责一个范围内的槽的数据存储。当请求过来时，首先根据请求的键，通过CRC16算法计算哈希并取模16384得到槽位，然后进入负责这个槽位的redis节点进行处理。集群中的每个redis节点都只有db0是可用的

### :point_right:**集群重定向？**

分两种情况，一种是向错误节点发送请求，二是迁移过程中发送请求

第一种情况下，向错误节点发送请求，节点向客户端返回一个MOVED标志和目标节点的位置，客户端根据返回来的目标节点的位置重定向到新的节点；第二种是ASK重定向，节点向客户端返回一个ASK错误标志同时携带目标节点地址，客户端重定向到目标节点，先发送一个ASKING标识，再去查询*（防止重定向循环，要求节点必须处理）*

### :point_right:Redis主从架构中数据丢失的情况？怎么解决？

1. 异步复制时数据丢失：主节点向从节点异步同步数据时，还没同步完，主节点宕机，丢失内存中的数据。即使后面主节点恢复了，在哨兵模式下选取从节点为新的主节点，由于没有同步完成，也会丢失数据
2. 集群脑裂：主从节点连接断开，哨兵认为主节点故障，投票选取新主节点，但是主节点并没有故障，仍在服务客户端，于是原主节点成为从节点后，内存数据被清空，丢失大量数据

## 应用

### :point_right:**知道PV访问、UV访问吗？怎么实现访问量计数？**

PV访问为page view，即页面单纯的点击量；UV为unique view，即访问该页面的独立用户量。UV访问量计数，可以使用hyperloglog来进行，它提供了不完全精准的去重统计方案，pfadd uv userID记录访问行为，pfcount返回估计的访问量

> 伯努利测试原理

### :point_right:**Redis实现队列的方法？**

- list
- zset（时间戳作value，可实现延时队列）
- pub/sub
- stream

### :point_right:**Redis缓存雪崩？穿透？击穿？解决方案？**

- 缓存雪崩是指缓存服务失效，大量的请求直接达到数据库上，可能导致数据库压力过大而宕机，最终导致整个服务系统的不可用。出现雪崩的原因可能有缓存服务器宕机、redis服务节点挂掉或者大量的键同时失效。针对雪崩的问题可以解决的策略有：① 搭建缓存集群，在一个节点失效后，不至于整个缓存服务都失效；② 如果是大量的键同时过期导致的，则可以令键的过期值加上一个随机数，避免让他们同时过期；③ 在这种情况发生的时候，及时对服务进行熔断或者降级
- 缓存穿透是指进行缓存中不存在的查询，如果进行大量缓存中不存在的查询，类似于查询一个不存在的行之类的，那么查询也会打到服务器上，造成服务器压力过大，可能发生宕机。解决的策略有：① 将这些查询请求的信息缓存在redis当中，有对应查询的时候返回一个固定的值。这样做需要注意的是：缓存是消耗空间的，其次，如果大量缓存了这种不存在的查询，可能导致在内存淘汰的时候将正常的键淘汰出去，可以考虑单独用一个redis节点来缓存这些内容，最后，当这些查询真的变成可用了的之后，还需要将之前那些缓存删除掉；② 可以采用布隆过滤器，将正常的查询存储到布隆过滤器里面，这样就一定能通过正常的查询，而非正常的查询可能通过，但概率很小
- 缓存击穿是指对于热点数据，即访问量很高的键，如果它过期了，这些请求可能发现缓存不存在，就去数据库里请求，就可能把数据库压垮。解决的策略有：① 采用分布式锁，每次请求这个热键先加锁，但这样可能影响效率；② 采用一个这样的算法：不令热键过期，但给他设置一个过期时间在后台，等到过期之后通过后台去更新这个热键的值，这样不怎么影响效率，但可能出现数据不一致问题

### :point_right:**Redis超卖问题怎么解决？**

超卖问题，首先问题要结合出现场景来说，超卖的场景：高并发。接着要明确问题的定义，超卖就是多个线程并发的拿取商品数量，接着去修改这个数量令其减一，最后将减过的值更新回去，由于这个过程是非原子的，所以可能导致商品数量减操作线程之间互相覆盖了，造成完成多个购买操作，但库存减的数目却比卖出去的实际数目要少。如果是单机服务器，当然可以用synchronized锁住方法，但在分布式系统中，一个请求会被分发到不同的服务节点，就必须得采用分布式锁了

分布式锁一般靠setnx指令来实现，setnx lock 1，存在这个键，上锁失败，否则成功，使用这个方法，需要注意放在finally块中进行解锁，和ReentrantLock一样的，否则在代码抛出异常时就永远无法解锁了

但在这种情况还存在问题，如果某服务器节点上锁后，宕机了，可能会导致永远加锁，解决的办法是添加过期时间

但这样还存在问题，就是在添加过期时间之前，节点宕机了，解决的方式就是合并成一条指令，set key EX seconds*（PX：millis）* NX；或者采用lua脚本

但这样还存在问题，比如说一个请求过来了加锁成功，但执行比较慢，执行过程中锁过期了，然后第二个线程进来执行，加锁，接着第一个线程执行完成，释放锁，但释放的是线程二的锁，这样可能会导致每个线程都释放了后面线程的锁，而且多个线程一起执行了。解决方法是，给分布式锁的value添加一个唯一标识比如说UUID，解锁时比对UUID，不匹配就解锁不了，注意比对UUID的动作和解锁的动作，也必须是原子性的，可以考虑lua

但这样还存在问题，确实不会解锁后面的线程了，但线程执行时间太长，锁失效的时候，其他线程也可以进入。所以说可以设置一个后台监控的线程，在锁解锁之前，监控持有锁的这个线程，如果仍在运行，给锁续命，这貌似就是Redission中的实现方式

还存在的问题有：分布式锁令操作串行化，或者当前Redis节点宕机之后，当前节点分布式锁就失效了。针对第一个问题，可以考虑搭建Redis集群并令请求分散到不同的Redis节点，每个小节点中给几种商品加锁，减小锁的粒度。针对第二个问题，可以考虑RedLock，每次加锁需要给超过半数的节点加锁才能成功，否则回滚。这样的话，操作同一个库存，就算这个节点上某线程加的锁因宕机失效了，其他线程也必须给超过半数的节点加锁成功才能实现，这时就做不到了

> 可以考虑用list放商品，或者decrby*（减成负数后需要回滚，所以decrby并回滚这一操作要求原子性）*

### :point_right:**Redis和数据库数据不一致的解决？**

出现场景：某线程更新数据库后卡住，另一个线程再次更新数据库并更新缓存，最初的线程恢复，更新缓存，导致缓存和数据库的值不一致

解决方案思路：

1. 不采取更新缓存这种操作，因为这是一个代价比较大的操作，缓存可能被经常更新，也可能导致不一致
2. Cache Aside，更新数据库的时候，先更新数据库，再删除缓存；读取缓存的时候，发现没有，就去数据库里面拿，并设置缓存。可能出现的问题：某线程读取缓存发现没有，去数据库中读取，此时卡了，另外的线程过来，发现缓存没有，更新了数据库并作删除缓存操作，最初的线程恢复，设置缓存，造成不一致
3. 延时双删，更新数据库后作两次删除缓存操作，之间隔一段时间。缺陷：时间不好确定，影响性能
4. 修改数据库的操作和更新缓存的操作打包成原子性，比如说上分布式锁。缺陷：太影响性能
5. Redission读写锁*（源码里是用lua封装的）*
6. 看场景，对缓存一致性要求不高的应用，可以直接简单设置个ttl

### :point_right:**Redis实现限流？**

- Redis官方方案1：设置key，ip+":"+ts，每来一个请求，进入事务，操作对应的键的value+1，同时设置过期时间以便key没用了之后自动清除，如果value大于阈值就返回异常。不能很好的处理边界情况
- Redis官方方案2：设置ip为key，过期时间设置为一秒，一秒内value大于阈值，则返回异常。频繁的key的删除，影响性能，边界情况处理不好
- 自己的想法：设计时间戳为key，过期时间为60秒，每次取历史数据时，先keys *统计key的数目，如果大于100则返回。频繁更新key，以及keys *是O(N)的，影响性能
- 滑动窗口法，窗口细化；漏桶法；令牌桶法；zset法

### :point_right:**知道哪些Redis客户端？对比一下**

jedis、lettuce、redission

- jedis：直接连接redis客户端，命令简单，但多线程下不安全
- lettuce：有连接池，多线程下每个线程都有连接实例，线程安全效率高*（ThreadLocal既视感？）*
- redission：封装了很多丰富的功能

### :point_right:**Redis应用场景？**

- string：缓存、计数器、限流、分布式锁
- hash：存储对象，优点：比起string，键更加集中；比起序列化后存，修改方便，商品库存这些可用到*（购物车）*
- list：消息队列、消息流
- set：抽奖*（srandmember/spop）*、共同关注*（sinter、sismember、sdiff，用于推荐用户等等）*、商品筛选
- 排行榜、限流器